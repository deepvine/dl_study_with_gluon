{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference\n",
    "* https://mxnet.incubator.apache.org/_modules/mxnet/gluon/rnn/rnn_layer.html\n",
    "* https://mxnet.incubator.apache.org/api/python/gluon/rnn.html#mxnet.gluon.rnn.RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet import autograd, nd\n",
    "from mxnet.gluon import nn, rnn\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "n_hidden_state = 10\n",
    "embedding_input = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden_size, num_layers, activation, layout, dropout, bidirectional, \n",
    "# i2h_weight_initializer, h2h_weight_initializer, i2h_bias_initializer, h2h_bias_initializer, input_size\n",
    "model = rnn.RNN(n_hidden_state, 1, layout = 'NTC', input_size = embedding_input, prefix='mdl_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.collect_params().initialize(mx.init.Xavier(), ctx = mx.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = model.begin_state(batch_size = 16)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"RNN-rolled.png\" alt=\"drawing\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image by http://colah.github.io/posts/2015-08-Understanding-LSTMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hiddens state size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5)\n",
      "(10,)\n",
      "(10, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "print(model.params['mdl_l0_i2h_weight'].data().shape)\n",
    "print(model.params['mdl_l0_i2h_bias'].data().shape)\n",
    "print(model.params['mdl_l0_h2h_weight'].data().shape)\n",
    "print(model.params['mdl_l0_h2h_bias'].data().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step = 1\n",
    "data = nd.random.normal(shape =(batch_size, time_step, embedding_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "\n",
      "[[ 0.823 -1.879  0.886  1.912  0.333]]\n",
      "<NDArray 1x5 @cpu(0)>\n",
      "\n",
      "[ 0.823 -1.879  0.886  1.912  0.333]\n",
      "<NDArray 5 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(data[0])\n",
    "print(data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(5 -> 10, NTC)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __data__: input tensor with shape (sequence_length, batch_size, input_size) when layout is “TNC”. For other layouts, dimensions are permuted accordingly using transpose() operator which adds performance overhead. Consider creating batches in TNC layout during data batching step.\n",
    "\n",
    "* __states__: initial recurrent state tensor with shape (num_layers, batch_size, num_hidden). If bidirectional is True, shape will instead be (2*num_layers, batch_size, num_hidden). If states is None, zeros will be used as default begin states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, state = model(data, initial_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __out__: output tensor with shape (sequence_length, batch_size, num_hidden) when layout is “TNC”. If bidirectional is True, output shape will instead be (sequence_length, batch_size, 2*num_hidden)\n",
    "\n",
    "* __out_states__: output recurrent state tensor with the same shape as states. If states is None out_states will not be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "2\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(out)) #N: batch_size\n",
    "print(len(out[0])) #T: sequence_length\n",
    "print(len(out[0][0])) #C: num_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "16\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(state))\n",
    "print(len(state[0])) #num_layers\n",
    "print(len(state[0][0])) #batch_size\n",
    "print(len(state[0][0][0])) #num_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
       "<NDArray 10 @cpu(0)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][0] == state[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2h_weight = model.params['mdl_l0_h2h_weight'].data()\n",
    "h2h_bias = model.params['mdl_l0_h2h_bias'].data()\n",
    "i2h_weight = model.params['mdl_l0_i2h_weight'].data()\n",
    "i2h_bias = model.params['mdl_l0_i2h_bias'].data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = nd.relu(nd.dot(dat[0][0], i2h_weight, transpose_b = True) + i2h_bias + nd.dot(h2h_weight, initial_state[0][0][0]) + h2h_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.652 0.103 0.    1.276 0.682 0.77  0.788 0.994 0.    0.764]\n",
      "[0.947 0.522 0.032 0.    0.    0.    0.    0.463 1.607 0.   ]\n",
      "[0.947 0.522 0.032 0.    0.    0.    0.    0.463 1.607 0.   ]\n"
     ]
    }
   ],
   "source": [
    "print(res.asnumpy())\n",
    "print(out[0][0].asnumpy())\n",
    "print(state[0][0][0].asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "1\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(out))\n",
    "print(len(out[0]))\n",
    "print(len(out[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "16\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(state))\n",
    "print(len(state[0]))\n",
    "print(len(state[0][0]))\n",
    "print(len(state[0][0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step = 2\n",
    "data = nd.random.normal(shape =(batch_size, time_step, embedding_input))\n",
    "out, state = model(data, initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.    0.    0.502 0.    0.    0.    0.638 0.    0.    0.   ]\n",
      "[0.    0.    0.502 0.    0.    0.    0.638 0.    0.    0.   ]\n"
     ]
    }
   ],
   "source": [
    "print(out[0][1].asnumpy())\n",
    "print(state[0][0][0].asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2h_weight = model.params['mdl_l0_h2h_weight'].data()\n",
    "h2h_bias = model.params['mdl_l0_h2h_bias'].data()\n",
    "i2h_weight = model.params['mdl_l0_i2h_weight'].data()\n",
    "i2h_bias = model.params['mdl_l0_i2h_bias'].data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_t1 = nd.relu(nd.dot(data[0][0], i2h_weight, transpose_b = True) + i2h_bias \\\n",
    "      + nd.dot(h2h_weight, initial_state[0][0][0]) + h2h_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.947 0.522 0.032 0.    0.    0.    0.    0.463 1.607 0.   ]\n",
      "[0.    0.    0.    1.085 0.    0.841 0.864 0.    0.    0.402]\n"
     ]
    }
   ],
   "source": [
    "print(out_t1.asnumpy())\n",
    "print(out[0][0].asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_t2 = nd.relu(nd.dot(dat[0][1], i2h_weight, transpose_b = True) + i2h_bias \\\n",
    "      + nd.dot(h2h_weight, out_t1) + h2h_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.    0.    0.502 0.    0.    0.    0.638 0.    0.    0.   ]\n",
      "[0.    0.    0.502 0.    0.    0.    0.638 0.    0.    0.   ]\n",
      "[0.    0.    0.502 0.    0.    0.    0.638 0.    0.    0.   ]\n"
     ]
    }
   ],
   "source": [
    "print(out_t2.asnumpy()) # calculation\n",
    "print(state[0][0][0].asnumpy()) # State at last time step\n",
    "print(out[0][1].asnumpy()) # Last time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
