{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-trained Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial refers to https://gluon-nlp.mxnet.io/examples/word_embedding/word_embedding.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from mxnet import gluon\n",
    "from mxnet import nd\n",
    "import gluonnlp as nlp\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"내년 1월 집권 후반기를 맞는 도널드 트럼프 미국 대통령이 개각을 예고했다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_tokenize(source_str, token_delim=' ', seq_delim='\\n'):\n",
    "    return filter(None, re.split(token_delim + '|' + seq_delim, source_str))\n",
    "counter = nlp.data.count_tokens(simple_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'내년': 1,\n",
       "         '1월': 1,\n",
       "         '집권': 1,\n",
       "         '후반기를': 1,\n",
       "         '맞는': 1,\n",
       "         '도널드': 1,\n",
       "         '트럼프': 1,\n",
       "         '미국': 1,\n",
       "         '대통령이': 1,\n",
       "         '개각을': 1,\n",
       "         '예고했다.': 1})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = nlp.Vocab(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unk>\n",
      "<pad>\n",
      "<bos>\n",
      "<eos>\n",
      "1월\n",
      "개각을\n",
      "내년\n",
      "대통령이\n",
      "도널드\n",
      "맞는\n",
      "미국\n",
      "예고했다.\n",
      "집권\n",
      "트럼프\n",
      "후반기를\n"
     ]
    }
   ],
   "source": [
    "for word in vocab.idx_to_token:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(vocab.token_to_idx[\"<unk>\"])\n",
    "print(vocab.token_to_idx[\"world\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attaching word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of data provided by gluon<br>\n",
    "https://github.com/dmlc/gluon-nlp/blob/d49a7896ae92307cf3c930f2eb2e3d516a278fe7/src/gluonnlp/_constants.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding file wiki.ko.npz is not found. Downloading from Gluon Repository. This may take some time.\n",
      "Downloading /home/chatbot/.mxnet/embedding/fasttext/wiki.ko.npz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/embeddings/fasttext/wiki.ko.npz...\n"
     ]
    }
   ],
   "source": [
    "fasttext_simple = nlp.embedding.create('fasttext', source='wiki.ko')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To attach the newly loaded word embeddings fasttext_simple to indexed words in vocab, we simply call vocab’s set_embedding method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.set_embedding(fasttext_simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see other available sources of pretrained word embeddings using the fastText algorithm, we can call text.embedding.list_sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['crawl-300d-2M',\n",
       " 'crawl-300d-2M-subword',\n",
       " 'wiki.aa',\n",
       " 'wiki.ab',\n",
       " 'wiki.ace',\n",
       " 'wiki.ady',\n",
       " 'wiki.af',\n",
       " 'wiki.ak',\n",
       " 'wiki.als',\n",
       " 'wiki.am']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.embedding.list_sources('fasttext')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)  # len(counter) + <unk>, <pad>, <bos>, <eos>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the vector of any token that is unknown to vocab is a zero vector.<br> \n",
    "Its length is equal to the vector dimension of the fastText word embeddings: 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.embedding['없는단어'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
       "<NDArray 300 @cpu(0)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.embedding['없는단어']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.embedding['개각을'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[-0.11939    0.14281   -0.4036    -0.09584   -0.24916    0.20381\n",
       "  0.035114   0.12061    0.40127    0.17465    0.10857    0.0728\n",
       " -0.12138    0.33747    0.022977   0.24363   -0.18804   -0.02665\n",
       " -0.28662    0.048179  -0.2089    -0.0092405 -0.058002   0.052719\n",
       "  0.081023   0.14211    0.06015   -0.16239    0.28023    0.055946\n",
       " -0.26147   -0.13596    0.17029   -0.016631  -0.11155   -0.13916\n",
       " -0.28639    0.33995   -0.029001   0.24099    0.013514  -0.017179\n",
       "  0.55403   -0.13183    0.29294   -0.14833    0.07291   -0.14361\n",
       "  0.15363   -0.060235  -0.25805   -0.16631   -0.13454   -0.087062\n",
       " -0.1284    -0.17891   -0.029614  -0.24379    0.33243   -0.088118\n",
       "  0.10899   -0.1572    -0.22881    0.22783   -0.086342   0.29453\n",
       "  0.012163  -0.19059    0.10463    0.18104    0.2668     0.035839\n",
       "  0.017008  -0.50608   -0.0053929 -0.4075    -0.16649   -0.059163\n",
       " -0.35484   -0.21731   -0.19367    0.24612    0.32474    0.19187\n",
       " -0.151     -0.3265     0.087657  -0.3476     0.49131    0.25075\n",
       " -0.14623    0.25247   -0.016366  -0.30423    0.016891   0.042107\n",
       " -0.18597    0.18119   -0.32228   -0.016109  -0.068033  -0.26218\n",
       " -0.46739   -0.254     -0.077502   0.12124   -0.24379    0.3642\n",
       " -0.2682     0.30795   -0.15783   -0.14829    0.21383   -0.11013\n",
       "  0.014896   0.072223   0.24639    0.1105    -0.29653   -0.038841\n",
       " -0.21673   -0.60032   -0.2988     0.11683   -0.012818  -0.19867\n",
       "  0.007966   0.22807    0.17729   -0.18768    0.054155  -0.10275\n",
       " -0.063596  -0.28615    0.019235  -0.24793   -0.26733   -0.38686\n",
       " -0.27518   -0.18504    0.22285    0.28668   -0.28421    0.0021753\n",
       " -0.67246   -0.074211   0.16519   -0.33751   -0.91923    0.029555\n",
       " -0.50062   -0.19062   -0.2137    -0.0079412  0.24213   -0.33988\n",
       "  0.1247     0.5188    -0.19771    0.080345   0.30719    0.072771\n",
       " -0.10086    0.085563   0.021206   0.18541    0.34668   -0.19585\n",
       "  0.16319    0.087321   0.11733   -0.013918  -0.23475   -0.34149\n",
       "  0.013338   0.45128    0.0075264 -0.46177    0.56655    0.09021\n",
       " -0.029375   0.60313   -0.50984   -0.19618    0.88321   -0.42334\n",
       "  0.46487   -0.15224    0.93547   -0.55463    0.19883    0.25908\n",
       " -0.20348    0.38221    0.17704   -0.20717   -0.25518   -0.015335\n",
       " -0.30229    0.038945   0.070941  -0.055069   0.11232    0.17953\n",
       " -0.27211   -0.06245   -0.068051   0.1383    -0.055658  -0.20538\n",
       " -0.0699     0.3324     0.11441    0.10042   -0.17413   -0.33024\n",
       "  0.34428    0.044411  -0.054174   0.2123     0.012687   0.056423\n",
       " -0.083241  -0.47731    0.39116    0.070133   0.36587    0.13482\n",
       " -0.028388  -0.024532  -0.20368    0.38678    0.081984   0.32352\n",
       " -0.19732   -0.31568    0.37069   -0.24314    0.41219   -0.50902\n",
       " -0.15358    0.36981    0.065239   0.031536  -0.27327   -0.13108\n",
       "  0.088282   0.044982  -0.073475  -0.49995   -0.054141  -0.3695\n",
       "  0.38515   -0.15238   -0.23191    0.16159   -0.21016   -0.046227\n",
       "  0.083165   0.019804  -0.30321    0.25172   -0.13169   -0.16312\n",
       "  0.055793   0.18474    0.14037    0.12808    0.21824    0.11772\n",
       "  0.26605    0.35948   -0.40711   -0.13898    0.3616     0.33763\n",
       "  0.26601    0.1659     0.15403    0.062066   0.35935    0.32396\n",
       " -0.21239    0.0073404 -0.3437     0.1462    -0.19669   -0.077243\n",
       " -0.16695    0.17989   -0.20961   -0.03308   -0.085972   0.58125\n",
       " -0.032262   0.50708   -0.47483   -0.10392    0.024599  -0.35417  ]\n",
       "<NDArray 300 @cpu(0)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.embedding['개각을']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is reference to embedding.TokenEmbedding<br>\n",
    "https://gluon-nlp.mxnet.io/api/embedding.html?highlight=embedding#gluonnlp.embedding.TokenEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here is where to start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gluonnlp.embedding.token_embedding.FastText at 0x7f128be6d128>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "879130"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fasttext_simple.token_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = fasttext_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1.]\n",
      "<NDArray 1 @cpu(0)>\n",
      "\n",
      "[-1.]\n",
      "<NDArray 1 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "def pearson_correlation(w2v, word1, word2, scores):\n",
    "    from scipy import stats\n",
    "    evaluator = nlp.embedding.evaluation.WordEmbeddingSimilarity(\n",
    "        idx_to_vec=w2v,\n",
    "        similarity_function=\"CosineSimilarity\")\n",
    "    evaluator.initialize(ctx=ctx)\n",
    "    evaluator.hybridize()\n",
    "    pred = evaluator(word1, word2)\n",
    "    scorr = stats.spearmanr(pred.asnumpy(), scores.asnumpy())\n",
    "    return(scorr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1.]\n",
      "<NDArray 1 @cpu(0)>\n",
      "\n",
      "[-1.]\n",
      "<NDArray 1 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "def cos_sim(x, y):\n",
    "    return nd.dot(x, y) / (nd.norm(x) * nd.norm(y))\n",
    "\n",
    "x = nd.array([1,2])\n",
    "y = nd.array([-1,-2])\n",
    "print(cos_sim(x,x))\n",
    "print(cos_sim(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[0.55882585]\n",
       "<NDArray 1 @cpu(0)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(vocab.embedding['개각을'], vocab.embedding['대통령이'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[0.2999336]\n",
       "<NDArray 1 @cpu(0)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(fasttext_simple.idx_to_vec[fasttext_simple.token_to_idx['왕']], fasttext_simple.idx_to_vec[fasttext_simple.token_to_idx['남자']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
